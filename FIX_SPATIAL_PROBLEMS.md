# ç©ºé—´ç»†èŠ‚ä¸§å¤±é—®é¢˜ä¿®å¤æ–¹æ¡ˆ

## ä¿®å¤ç­–ç•¥æ¦‚è§ˆ

æ ¹æ®è¯Šæ–­ï¼Œé‡‡ç”¨**ä¸‰å±‚é€’è¿›å¼ä¿®å¤**ï¼š

### ç¬¬1å±‚ï¼šæ•°æ®å±‚é¢ï¼ˆå¿«é€Ÿè§æ•ˆï¼Œ1-2å°æ—¶ï¼‰
1. **æå€¼é‡é‡‡æ ·** - å¢åŠ é«˜æ±¡æŸ“/ä½æ±¡æŸ“æ ·æœ¬æƒé‡
2. **æ•°æ®å¢å¼º** - ç”Ÿæˆæå€¼è¾¹ç•Œæ ·æœ¬
3. **å½’ä¸€åŒ–æ”¹è¿›** - ä½¿ç”¨åˆ†ä½æ•°å½’ä¸€åŒ–è€Œémin-max

### ç¬¬2å±‚ï¼šæŸå¤±å‡½æ•°ï¼ˆä¸­ç­‰æŠ•å…¥ï¼Œ2-3å°æ—¶ï¼‰
1. **æ¢¯åº¦çº¦æŸæŸå¤±** - å¼ºåˆ¶é¢„æµ‹æ¢¯åº¦æ¥è¿‘çœŸå®
2. **æ„ŸçŸ¥æŸå¤±** - é«˜é¢‘ç»†èŠ‚ä¿ç•™
3. **æå€¼èšç„¦æŸå¤±** - é«˜æƒé‡å¤„ç†æç«¯å€¼

### ç¬¬3å±‚ï¼šæ¨¡å‹æ¶æ„ï¼ˆé‡æŠ•å…¥ï¼Œ4-6å°æ—¶ï¼‰
1. **éšå±‚æ‰©å±•** - 128â†’256ç»´
2. **è·³è¿æ¥** - ä¿ç•™ç»†èŠ‚ä¿¡æ¯
3. **å¤šå°ºåº¦ç›‘ç£** - ä¸åŒåˆ†è¾¨ç‡åŒæ—¶å­¦ä¹ 

---

## âœ… ç¬¬1å±‚ä¿®å¤ï¼šç«‹å³å®æ–½

### æ–¹æ¡ˆ1Aï¼šæå€¼é‡é‡‡æ · + æŸå¤±æƒé‡è°ƒæ•´

**æ–‡ä»¶ä¿®æ”¹ï¼š** `losses/loss_functions.py`

```python
# æ·»åŠ åŠ æƒMSEæŸå¤±ï¼Œå¼ºè°ƒæå€¼
class WeightedMSELoss(nn.Module):
    def __init__(self, extreme_weight=2.0, global_min=0.0, global_max=229.13):
        super().__init__()
        self.extreme_weight = extreme_weight
        self.global_min = global_min
        self.global_max = global_max
        
    def forward(self, pred, target, mask=None):
        # è®¡ç®—æƒé‡ï¼šæå€¼(>90%åˆ†ä½)ç»™äºˆ2å€æƒé‡
        normalized = (target - self.global_min) / (self.global_max - self.global_min)
        q90 = torch.quantile(normalized[mask>0], 0.90) if mask is not None else torch.quantile(normalized, 0.90)
        q10 = torch.quantile(normalized[mask>0], 0.10) if mask is not None else torch.quantile(normalized, 0.10)
        
        # æå€¼æ ·æœ¬æƒé‡æå‡
        weights = torch.ones_like(target)
        weights[normalized > q90] = self.extreme_weight
        weights[normalized < q10] = self.extreme_weight
        
        loss = (weights * (pred - target)**2 * mask).sum() / mask.sum()
        return loss
```

**åœ¨ `train.py` ä¸­ä½¿ç”¨ï¼š**

```python
# ç¬¬45è¡Œå·¦å³ï¼Œä¿®æ”¹æŸå¤±å‡½æ•°
from losses.loss_functions import WeightedMSELoss

# åˆå§‹åŒ–
pred_loss = WeightedMSELoss(extreme_weight=2.0, 
                            global_min=train_dataset.global_min,
                            global_max=train_dataset.global_max)

# è®¡ç®—æŸå¤±
pred_error = pred_loss(pred, target, mask)  # æ›¿æ¢åŸæ¥çš„ F.mse_loss
```

**é¢„æœŸæ•ˆæœï¼š** RÂ²ç»´æŒï¼ŒRMSEÂ±0%, ä½†æ¢¯åº¦ä¿ç•™ç‡ 0.54â†’0.65, æå€¼è¡¨ç°æ”¹å–„

---

### æ–¹æ¡ˆ1Bï¼šæ¢¯åº¦çº¦æŸæŸå¤±ï¼ˆæœ€æœ‰æ•ˆï¼‰

**æ–‡ä»¶ä¿®æ”¹ï¼š** `losses/loss_functions.py` æœ«å°¾æ·»åŠ 

```python
class GradientConstraintLoss(nn.Module):
    """å¼ºåˆ¶é¢„æµ‹æ¢¯åº¦æ¥è¿‘çœŸå®æ¢¯åº¦"""
    def __init__(self, weight=0.1):
        super().__init__()
        self.weight = weight
        
    def forward(self, pred, target, mask=None):
        # è®¡ç®—æ¢¯åº¦
        pred_gy, pred_gx = torch.gradient(pred, dim=[2, 3])
        target_gy, target_gx = torch.gradient(target, dim=[2, 3])
        
        # è®¡ç®—æ¢¯åº¦å¤§å°
        pred_grad = torch.sqrt(pred_gx**2 + pred_gy**2 + 1e-6)
        target_grad = torch.sqrt(target_gx**2 + target_gy**2 + 1e-6)
        
        # æ¢¯åº¦ä¸€è‡´æ€§æŸå¤±
        if mask is not None:
            grad_loss = F.mse_loss(pred_grad * mask, target_grad * mask)
        else:
            grad_loss = F.mse_loss(pred_grad, target_grad)
        
        return self.weight * grad_loss
```

**åœ¨ `train.py` ä¸­ä½¿ç”¨ï¼ˆç¬¬185è¡Œï¼‰ï¼š**

```python
# åˆå§‹åŒ–
from losses.loss_functions import GradientConstraintLoss
grad_loss_fn = GradientConstraintLoss(weight=0.05)

# åœ¨train loopä¸­ï¼ˆç¬¬185è¡Œï¼‰
pred_mse = F.mse_loss(pred, target, reduction='none')
pred_mse = (pred_mse * mask).sum() / mask.sum()
grad_loss = grad_loss_fn(pred, target, mask)  # æ–°å¢

total_loss = pred_mse + grad_loss  # æ›¿æ¢åŸæ¥çš„åªæœ‰pred_mse
```

**é¢„æœŸæ•ˆæœï¼š** æ¢¯åº¦ä¿ç•™ç‡ 0.54â†’0.85+, RMSE+2-3%, RÂ²-0.02

---

### æ–¹æ¡ˆ1Cï¼šæ›´æ–° config å‚æ•°ï¼ˆç«‹å³ç”Ÿæ•ˆï¼‰

**æ–‡ä»¶ä¿®æ”¹ï¼š** `config/__init__.py`

```python
# ç¬¬45è¡Œå·¦å³ï¼Œä¿®æ”¹
WEIGHT_SPECTRAL = 0.00001  # åŸæ¥0.001ï¼Œå‡å°Koopmançº¦æŸ
LATENT_DIM = 256  # åŸæ¥128ï¼Œå¢åŠ è¡¨è¾¾åŠ›
CLAMP_OUTPUT = True  # ä¿æŒ[0,1]èŒƒå›´

# æ–°å¢å‚æ•°
GRADIENT_LOSS_WEIGHT = 0.05  # æ¢¯åº¦æŸå¤±æƒé‡
EXTREME_VALUE_WEIGHT = 2.0   # æå€¼æ ·æœ¬æƒé‡
```

---

## ğŸ“‹ å®æ–½é¡ºåºï¼ˆæ¨èï¼‰

### **æ­¥éª¤1ï¼šå¿«é€ŸéªŒè¯ï¼ˆ15åˆ†é’Ÿï¼‰**
```bash
# åªä¿®æ”¹configï¼Œç«‹å³è®­ç»ƒ
# 1. ç¼–è¾‘ config/__init__.py
#    - WEIGHT_SPECTRAL = 0.00001
#    - LATENT_DIM = 256
# 2. è¿è¡Œ
python train.py
# 3. è§‚å¯Ÿæ¢¯åº¦æ˜¯å¦æ”¹å–„
```

### **æ­¥éª¤2ï¼šæ·»åŠ æ¢¯åº¦æŸå¤±ï¼ˆ30åˆ†é’Ÿï¼‰**
```bash
# 1. ç¼–è¾‘ losses/loss_functions.pyï¼Œæ·»åŠ  GradientConstraintLoss
# 2. ç¼–è¾‘ train.py ç¬¬185è¡Œï¼Œé›†æˆæ¢¯åº¦æŸå¤±
# 3. è¿è¡Œ
python train.py
# 4. æ£€æŸ¥æŒ‡æ ‡è¾“å‡º
```

### **æ­¥éª¤3ï¼šæå€¼é‡é‡‡æ ·ï¼ˆ45åˆ†é’Ÿï¼‰**
```bash
# 1. ç¼–è¾‘ losses/loss_functions.pyï¼Œæ·»åŠ  WeightedMSELoss
# 2. ç¼–è¾‘ train.py ç¬¬45è¡Œï¼Œä½¿ç”¨åŠ æƒæŸå¤±
# 3. è¿è¡Œ
python train.py
# 4. å¯¹æ¯”é¢„æµ‹æœ€å¤§å€¼æ˜¯å¦æå‡
```

---

## ä»£ç å®æ–½ç»†èŠ‚

### ä¿®æ”¹1ï¼šconfig/__init__.py

```python
# ç¬¬44-48è¡Œï¼Œæ›¿æ¢ä¸ºï¼š
WEIGHT_SPECTRAL = 0.00001      # å‡å°Koopmanè°±çº¦æŸ
LATENT_DIM = 256               # å¢åŠ éšå±‚ç»´åº¦
GRADIENT_LOSS_WEIGHT = 0.05    # æ–°å¢ï¼šæ¢¯åº¦æŸå¤±æƒé‡
EXTREME_VALUE_WEIGHT = 2.0     # æ–°å¢ï¼šæå€¼æƒé‡
```

### ä¿®æ”¹2ï¼šlosses/loss_functions.pyï¼ˆæœ«å°¾æ·»åŠ ï¼‰

```python
# æ–‡ä»¶æœ«å°¾æ·»åŠ è¿™ä¸¤ä¸ªç±»

class WeightedMSELoss(torch.nn.Module):
    """æ ¹æ®å€¼åŸŸèŒƒå›´å¯¹æ ·æœ¬è¿›è¡Œæƒé‡åŒ–"""
    def __init__(self, extreme_weight=2.0, global_min=0.0, global_max=229.13):
        super().__init__()
        self.extreme_weight = extreme_weight
        self.q_min = global_min
        self.q_max = global_max
        
    def forward(self, pred, target, mask=None):
        # å½’ä¸€åŒ–åˆ°[0,1]
        norm_target = (target - self.q_min) / (self.q_max - self.q_min + 1e-8)
        
        # è®¡ç®—åˆ†ä½æ•°é˜ˆå€¼
        if mask is not None:
            valid_vals = norm_target[mask > 0.5]
        else:
            valid_vals = norm_target.reshape(-1)
        
        q90 = torch.quantile(valid_vals, 0.90)
        q10 = torch.quantile(valid_vals, 0.10)
        
        # åˆ›å»ºæƒé‡çŸ©é˜µ
        weights = torch.ones_like(target)
        weights[(norm_target > q90) | (norm_target < q10)] = self.extreme_weight
        
        # è®¡ç®—åŠ æƒMSE
        se = (pred - target) ** 2
        if mask is not None:
            weighted_loss = (se * weights * mask).sum() / (mask.sum() + 1e-8)
        else:
            weighted_loss = (se * weights).mean()
        
        return weighted_loss


class GradientConstraintLoss(torch.nn.Module):
    """æ¢¯åº¦ä¸€è‡´æ€§æŸå¤±ï¼šå¼ºåˆ¶é¢„æµ‹æ¢¯åº¦æ¥è¿‘çœŸå®æ¢¯åº¦"""
    def __init__(self, weight=0.1):
        super().__init__()
        self.weight = weight
        
    def forward(self, pred, target, mask=None):
        # è®¡ç®—æ¢¯åº¦ (æ²¿Hå’ŒWç»´åº¦)
        # ä½¿ç”¨torch.gradientï¼ˆPyTorch 2.4+ï¼‰æˆ–æ‰‹åŠ¨è®¡ç®—
        pred_gy = pred[:, :, 1:, :] - pred[:, :, :-1, :]
        pred_gx = pred[:, :, :, 1:] - pred[:, :, :, :-1]
        target_gy = target[:, :, 1:, :] - target[:, :, :-1, :]
        target_gx = target[:, :, :, 1:] - target[:, :, :, :-1]
        
        # æ¢¯åº¦å¹…å€¼
        pred_grad = torch.sqrt(pred_gx[:, :, :, :-1]**2 + pred_gy[:, :, :-1, :]**2 + 1e-6)
        target_grad = torch.sqrt(target_gx[:, :, :, :-1]**2 + target_gy[:, :, :-1, :]**2 + 1e-6)
        
        # æ¢¯åº¦æŸå¤±
        grad_loss = torch.nn.functional.mse_loss(pred_grad, target_grad)
        
        return self.weight * grad_loss
```

### ä¿®æ”¹3ï¼štrain.pyï¼ˆç¬¬40-50è¡Œï¼‰

```python
# åŸä»£ç ï¼š
# from losses.loss_functions import SpectralLoss

# ä¿®æ”¹ä¸ºï¼š
from losses.loss_functions import SpectralLoss, WeightedMSELoss, GradientConstraintLoss
```

### ä¿®æ”¹4ï¼štrain.pyï¼ˆç¬¬180-200è¡Œï¼‰è®­ç»ƒå¾ªç¯

```python
# åŸä»£ç ï¼š
# pred_error = F.mse_loss((pred - true_data)**2 * valid_mask)

# ä¿®æ”¹ä¸ºï¼š
# ä½¿ç”¨åŠ æƒMSE
pred_error = weighted_mse(pred, true_data, valid_mask)

# æ·»åŠ æ¢¯åº¦çº¦æŸ
grad_penalty = gradient_constraint(pred, true_data, valid_mask)

# æ€»æŸå¤±
total_loss = pred_error + grad_penalty + spectral_loss
```

---

## âš™ï¸ å…³é”®å‚æ•°è°ƒä¼˜è¡¨

| å‚æ•° | ä¿å®ˆè®¾ç½® | æ¨èè®¾ç½® | æ¿€è¿›è®¾ç½® |
|------|--------|--------|--------|
| LATENT_DIM | 128 | **256** | 512 |
| GRADIENT_LOSS_WEIGHT | 0.01 | **0.05** | 0.10 |
| EXTREME_VALUE_WEIGHT | 1.5 | **2.0** | 3.0 |
| WEIGHT_SPECTRAL | 0.0001 | **0.00001** | 0 |

---

## ğŸ“Š é¢„æœŸæ”¹è¿›æ•ˆæœ

| æŒ‡æ ‡ | å½“å‰ | ç›®æ ‡ | å®ç°æ–¹å¼ |
|------|------|------|--------|
| æ¢¯åº¦ä¿ç•™ç‡ | 54% | **85%** | æ¢¯åº¦çº¦æŸæŸå¤± |
| æå€¼è¦†ç›–ç‡ | 70% | **90%** | éšå±‚æ‰©å±•+æƒé‡ |
| NRMSE% | 109.6% | **25%** | å¤šç®¡é½ä¸‹ |
| RÂ² | 0.76 | **0.75-0.80** | ç•¥å¾®ä¸‹é™ï¼Œä½†ç©ºé—´è´¨é‡â†‘ |
| æ¢¯åº¦å¹…å€¼ | 2.13 | **3.2+** | æ¢¯åº¦æŸå¤± |

---

## ğŸ§ª éªŒè¯æ–¹æ³•

æ¯æ¬¡ä¿®æ”¹åè¿è¡Œï¼š

```bash
# 1. è®­ç»ƒ
python train.py

# 2. åˆ†æç©ºé—´ç‰¹å¾
python spatial_analysis.py

# 3. æ£€æŸ¥è¾“å‡ºä¸­çš„å…³é”®æŒ‡æ ‡
# - æ¢¯åº¦å¹…å€¼æ˜¯å¦ä»2.13æå‡åˆ°3.0+
# - æå€¼(æœ€å¤§å€¼)æ˜¯å¦ä»112æå‡åˆ°140+
# - NRMSE%æ˜¯å¦ä¸‹é™
```

---

## ğŸš€ å¿«é€Ÿå¯åŠ¨ï¼ˆå¤åˆ¶å³ç”¨ï¼‰

### ç¬¬1æ­¥ï¼šä¿®æ”¹ config/__init__.py
```python
WEIGHT_SPECTRAL = 0.00001
LATENT_DIM = 256
GRADIENT_LOSS_WEIGHT = 0.05
EXTREME_VALUE_WEIGHT = 2.0
```

### ç¬¬2æ­¥ï¼šè¿è¡Œæµ‹è¯•
```bash
python train.py
python spatial_analysis.py
```

### ç¬¬3æ­¥ï¼šè§‚å¯Ÿæ”¹è¿›
æŸ¥çœ‹ `spatial_feature_analysis.png` ä¸­çš„æ¢¯åº¦å¯¹æ¯”

---

## âš ï¸ é£é™©ä¸è§„é¿

| é£é™© | ç—‡çŠ¶ | è§„é¿æ–¹æ¡ˆ |
|------|------|--------|
| è¿‡æ‹Ÿåˆ | RÂ²ä¸‹é™>0.10 | é™ä½ GRADIENT_LOSS_WEIGHT åˆ°0.02 |
| æ¢¯åº¦çˆ†ç‚¸ | è®­ç»ƒloss NaN | ä½¿ç”¨ gradient_clipping |
| å†…å­˜æº¢å‡º | CUDA OOM | é™ä½ LATENT_DIM åˆ°192 |
| æ”¶æ•›å›°éš¾ | 150 epochåæ— æ”¹å–„ | å¢åŠ  WEIGHT_DECAY æˆ–é™ä½å­¦ä¹ ç‡ |

---

## ğŸ“ å®æ–½æ£€æŸ¥æ¸…å•

- [ ] ä¿®æ”¹ config/__init__.py (LATENT_DIM, WEIGHT_SPECTRALç­‰)
- [ ] æ·»åŠ  WeightedMSELoss åˆ° losses/loss_functions.py
- [ ] æ·»åŠ  GradientConstraintLoss åˆ° losses/loss_functions.py
- [ ] ä¿®æ”¹ train.py å¯¼å…¥è¯­å¥
- [ ] ä¿®æ”¹ train.py è®­ç»ƒå¾ªç¯ä½¿ç”¨æ–°æŸå¤±
- [ ] è¿è¡Œ python train.py éªŒè¯è®­ç»ƒæ­£å¸¸
- [ ] è¿è¡Œ python spatial_analysis.py æ£€æŸ¥æ¢¯åº¦æ”¹å–„
- [ ] å¯¹æ¯” metrics_summary_comprehensive.png

---

**é¢„æœŸæ€»è€—æ—¶ï¼š1-2å°æ—¶å®Œå…¨å®æ–½ + 2å°æ—¶è®­ç»ƒ = 3-4å°æ—¶**
